{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paquetes a usar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En esta primera parte realizamos una limpieza de los datos para que no hayan duplicados, y luego elegimos solo los campos que nos interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lectura del archivo como DataFrame\n",
    "df = pd.read_csv(\"universities_followers_2022.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university\n",
      "user_id\n",
      "user_name\n",
      "number_tweets\n",
      "friends_count\n",
      "followers_count\n",
      "created_at\n"
     ]
    }
   ],
   "source": [
    "for name in df.columns: print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID totales:  29245\n",
      "ID totales sin duplicados:  26101\n"
     ]
    }
   ],
   "source": [
    "## Borrado de user_id duplicadas\n",
    "print(\"ID totales: \", df.user_id.count())\n",
    "df.drop_duplicates(subset=\"user_id\",inplace=True)\n",
    "print(\"ID totales sin duplicados: \",df.user_id.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Guardado de ID (numerico y string) sin duplicadods como csv\n",
    "df.to_csv(\"clean_int_id.csv\",sep=\" \",columns=[\"user_id\",\"followers_count\"],header=False, index=False)\n",
    "df.to_csv(\"clean_str_id.csv\",sep=\" \",columns=[\"user_name\",\"followers_count\"],header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A continuación generamos 4 sets de datos que usaremos en main para las búsquedas.\n",
    "\n",
    "Estos set de datos son:\n",
    "1. Números int que se encuentran en las estructuras \n",
    "2. Cadenas string que se encuentran en las estructuras\n",
    "3. Números int que no se encuentran en las estructuras\n",
    "4. Cadenas string que no se encuentran en las estructuras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set de datos (a partir del df) para realizar busqueda en main\n",
    "sample_int = df[\"user_id\"].sample(300,replace=False)\n",
    "sample_int.to_csv(\"in_search_int.csv\",sep=\" \",header=False,index=False)\n",
    "sample_str = df[\"user_name\"].sample(300,replace=False)\n",
    "sample_str.to_csv(\"in_search_str.csv\",sep=\" \",header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    26101\n",
      "Name: user_id, dtype: int64\n",
      "300\n",
      "False    26101\n",
      "Name: user_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Generamos un array aleatorio de 300 enteros en el rango mostrado\n",
    "not_sample_int = np.random.randint(1,10000000,size=300,)\n",
    "\n",
    "## Chequeamos que ninguno se encuentre en el dataframe\n",
    "is_in = df[\"user_id\"].isin(not_sample_int)\n",
    "print(is_in.value_counts())\n",
    "\n",
    "## Ahora generamos strings de forma aleatoria a partir del string \"murcielagos\"\n",
    "abc = \"murcielagos\"\n",
    "\n",
    "combinaciones = [''.join(comb) for comb in iter.combinations(abc,5)]\n",
    "words = pd.DataFrame(combinaciones)[0:300]\n",
    "print(words.size)\n",
    "\n",
    "## Chequeamos que no se encuentren en el DataFrame\n",
    "is_in =df[\"user_name\"].isin(words)\n",
    "print(is_in.value_counts())\n",
    "\n",
    "## Guardamos cada conjunto de datos en csv\n",
    "pd.DataFrame(not_sample_int).to_csv(\"not_in_search_int.csv\",sep=\" \", header=False,index=False)\n",
    "words.to_csv(\"not_in_search_str.csv\",sep=\" \", header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
